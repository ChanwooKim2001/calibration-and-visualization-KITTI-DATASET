{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0926ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from pythreejs import *\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4482d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(370, 1224, 3)\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "calibration_file_path = \"kitti_object_vis-master/data/object/training/calib/000000.txt\"\n",
    "image_file_path = \"kitti_object_vis-master/data/object/training/image_2/000000.png\"\n",
    "lidar_data_path = \"kitti_object_vis-master/data/object/training/velodyne/000000.bin\"\n",
    "\n",
    "stream = open(image_file_path, \"rb\")\n",
    "bytes = bytearray(stream.read())\n",
    "numpyarray = np.asarray(bytes, dtype=np.uint8)\n",
    "image_color = cv2.imdecode(numpyarray, cv2.IMREAD_UNCHANGED)\n",
    "image_color = image_color[:, :, (2, 1, 0)]  # BGR -> RGB\n",
    "print(image_color.shape)\n",
    "image_color_row = image_color.shape[0]\n",
    "image_color_column = image_color.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ceea0787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read calibration data\n",
    "with open(calibration_file_path, 'r') as fid:\n",
    "    lines = fid.readlines()\n",
    "    for i in range(7):\n",
    "        lines[i] = lines[i].strip().split(' ')\n",
    "        del lines[i][0]\n",
    "        lines[i] = ' '.join(lines[i])\n",
    "\n",
    "    P0 = np.fromstring(lines[0], dtype=float, sep=' ')\n",
    "    P1 = np.fromstring(lines[1], dtype=float, sep=' ')\n",
    "    P2 = np.fromstring(lines[2], dtype=float, sep=' ')\n",
    "    P3 = np.fromstring(lines[3], dtype=float, sep=' ')\n",
    "    R0_rect = np.fromstring(lines[4], dtype=float, sep=' ')\n",
    "    Tr_velo_to_cam = np.fromstring(lines[5], dtype=float, sep=' ')\n",
    "    Tr_imu_to_velo = np.fromstring(lines[6], dtype=float, sep=' ')\n",
    "    Tr_cam_to_road = np.fromstring(lines[7], dtype=float, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a7386bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read LiDAR data\n",
    "data = np.fromfile(lidar_data_path, dtype=np.float32).reshape(-1, 4)\n",
    "# Perform LiDAR-to-Image mapping\n",
    "R0 = R0_rect.reshape(3,3)\n",
    "Tr = Tr_velo_to_cam.reshape(3,4)\n",
    "p2 = P2.reshape(3,4)\n",
    "XYZ = data[:,:3].T\n",
    "\n",
    "XYZ1 = np.vstack((XYZ, np.ones(data.shape[0])))\n",
    "XYZ1 = np.dot(R0, np.dot(Tr, XYZ1))\n",
    "XYZ1 = np.vstack((XYZ1, np.ones(XYZ1.T.shape[0])))\n",
    "xy1 = np.dot(p2,XYZ1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3915471a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06035061]\n",
      " [ 0.00175693]\n",
      " [-0.00497187]\n",
      " [ 0.99816331]]\n"
     ]
    }
   ],
   "source": [
    "p2=P2.reshape(3,4)\n",
    "\n",
    "#separate K, R, and T through the decomposeProjectionMatrix function of openCV.\n",
    "k2,r2,t2,_,_,_,_= cv2.decomposeProjectionMatrix(p2)\n",
    "\n",
    "#The reason why there are four elements of t2 is that when decompose is performed, T is cut off based on the size of 4X4.\n",
    "#Therefore, the last element is unnecessary.\n",
    "print(t2)\n",
    "t2=t2[:3,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4e5cb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20285, 2)\n"
     ]
    }
   ],
   "source": [
    "weight = xy1[2, :]\n",
    "x=xy1[0,:]/weight\n",
    "y=xy1[1,:]/weight\n",
    "k = np.where(weight > 0)[0]\n",
    "valid_xy1=xy1.T[k]\n",
    "\n",
    "#PCD information in world coordinate system\n",
    "valid_xy1=np.dot(np.linalg.inv(k2),valid_xy1.T)\n",
    "valid_xy1=valid_xy1.T-t2\n",
    "valid_xy1=np.dot(np.linalg.inv(r2),valid_xy1.T)\n",
    "depth_camera02=valid_xy1.T\n",
    "\n",
    "x=x[k].reshape(-1,1)\n",
    "y=y[k].reshape(-1,1)\n",
    "w=weight[k].reshape(-1,1)\n",
    "xy=np.hstack((x,y))\n",
    "\n",
    "xy_index11=np.where(xy[:,0]<image_color_column)\n",
    "xy_index12=np.where(xy[:,0]>=0)\n",
    "xy_index21=np.where(xy[:,1]<image_color_row)\n",
    "xy_index22=np.where(xy[:,1]>=0)\n",
    "xy_index1=np.intersect1d(xy_index11,xy_index12)\n",
    "xy_index2=np.intersect1d(xy_index21,xy_index22)\n",
    "\n",
    "#xy_index: Index of point clouds that come within the scope of the camera's view\n",
    "xy_index=np.intersect1d(xy_index1,xy_index2)\n",
    "reshaped_xy=xy[xy_index]\n",
    "print(reshaped_xy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "751f076a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(452880, 3)\n",
      "[[0.000e+00 0.000e+00 1.700e+01 2.200e+01 1.800e+01]\n",
      " [0.000e+00 1.000e+00 1.600e+01 2.400e+01 2.800e+01]\n",
      " [0.000e+00 2.000e+00 2.500e+01 2.900e+01 3.300e+01]\n",
      " ...\n",
      " [3.690e+02 1.221e+03 2.200e+01 3.000e+01 3.700e+01]\n",
      " [3.690e+02 1.222e+03 2.200e+01 2.900e+01 3.800e+01]\n",
      " [3.690e+02 1.223e+03 2.000e+01 3.000e+01 3.500e+01]]\n"
     ]
    }
   ],
   "source": [
    "RGB_to_world_coordinate=np.zeros((image_color_row*image_color_column,2)).reshape(-1,2)\n",
    "\n",
    "#Save the (x,y) coordinates of the picture in matrix form in pixel coordinate\n",
    "for i in range(image_color_row):\n",
    "    for j in range(image_color_column):\n",
    "        RGB_to_world_coordinate[i*1224+j,0]=i\n",
    "        RGB_to_world_coordinate[i*1224+j,1]=j\n",
    "image_color=image_color.reshape(-1,3)\n",
    "print(image_color.shape)\n",
    "\n",
    "#The (x,y) coordinates of the pixel and the (r,g,b) information are hstacked.\n",
    "RGB_tmp=np.hstack((RGB_to_world_coordinate,image_color))\n",
    "print(RGB_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b585285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since each coordinate information of a pixel is an integer, all points belonging to one pixel may have the same color.\n",
    "int_xy=reshaped_xy.astype(int)\n",
    "RGB=np.zeros((len(int_xy.T[0]),3))\n",
    "for i in range(len(int_xy.T[0])):\n",
    "    index_RGB_tmp=int_xy[i,1]*image_color_column+int_xy[i,0]\n",
    "    RGB[i]=RGB_tmp[index_RGB_tmp,2:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5107a944",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_point_tmp=np.vstack((reshaped_xy.T,np.ones(reshaped_xy.T[0].shape)))\n",
    "\n",
    "image_point_tmp=np.dot(np.linalg.inv(k2),image_point_tmp)\n",
    "image_point_tmp=image_point_tmp.T-t2\n",
    "image_point_tmp=np.dot(np.linalg.inv(r2),image_point_tmp.T)\n",
    "\n",
    "#When image_point is displayed, The point cloud is taken in the form of a photo.\n",
    "image_point=np.hstack((image_point_tmp.T,RGB))\n",
    "#When image_point2 is displayed, The point cloud is displayed as 3D PCD map.\n",
    "image_point2=np.hstack((depth_camera02[xy_index],RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecf70bf6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0\n"
     ]
    }
   ],
   "source": [
    "Fov= 2*math.atan(p2[1,1]/p2[0,0])*(180/pi)\n",
    "print(Fov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a025c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\loyid\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pythreejs\\traits.py:257: UserWarning: 64-bit data types not supported for WebGL data, casting to 32-bit.\n",
      "  warnings.warn('64-bit data types not supported for WebGL '\n"
     ]
    }
   ],
   "source": [
    "normalized_RGB_color = image_point2 / 255.0\n",
    "geometry = BufferGeometry(\n",
    "     attributes={\n",
    "        'position': BufferAttribute(image_point2[:,:3], normalized=False),\n",
    "        'color': BufferAttribute(normalized_RGB_color[:,3:6], normalized=True)\n",
    "     }\n",
    " )\n",
    "\n",
    "material = PointsMaterial(size=0.1, vertexColors='VertexColors')\n",
    "point=Points(geometry=geometry, material=material)\n",
    "\n",
    "camera = PerspectiveCamera(up=[0,0,1], position=[0,-10,-10], near=0.01, aspect=400/300)\n",
    "key_light = DirectionalLight(position=[0, 10, 10])\n",
    "ambient_light = AmbientLight()\n",
    "scene=Scene(children=[point,camera,key_light,ambient_light], background=None)\n",
    "scene.add(AxesHelper(size=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad1b10c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02236671 -0.05967891 -0.332549  ]\n"
     ]
    }
   ],
   "source": [
    "lidar_position=np.dot(R0,np.dot(Tr,[0,0,0,1]))\n",
    "print(lidar_position)\n",
    "\n",
    "#PointLightHelper for expressing lidar sensor's position in the world coordinate system\n",
    "point_light = PointLight(color=\"#ffffff\", intensity=1, distance=100)\n",
    "lidar_position=(lidar_position[0],lidar_position[1],lidar_position[2])\n",
    "point_light_helper = PointLightHelper(point_light, position=lidar_position, distance=0.1, sphereSize=0.1)\n",
    "scene.add(point_light)\n",
    "scene.add(point_light_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef22273a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.06035061 -0.00175693  0.00497187]\n"
     ]
    }
   ],
   "source": [
    "cam_position=[0,0,0]\n",
    "cam_position=np.dot(np.linalg.inv(k2),cam_position)\n",
    "cam_position=cam_position-t2\n",
    "cam_position=np.dot(np.linalg.inv(r2),cam_position)\n",
    "print(cam_position)\n",
    "\n",
    "near_condition=np.where(image_point2[:,0]>=0)\n",
    "near=np.min(image_point2[near_condition,0])\n",
    "far=np.max(image_point2[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f3b26de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0049718674293782\n",
      "1.0049718674293782\n"
     ]
    }
   ],
   "source": [
    "#image_point's depth: Focal length\n",
    "print(np.min(image_point[:,2]))\n",
    "print(np.max(image_point[:,2]))\n",
    "near=np.max(image_point[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0250dbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam=PerspectiveCamera(up=[0,0,-1], position=(cam_position[0],cam_position[1],cam_position[2]), aspect=image_color_row/image_color_column, fov=Fov, near=near, far=far)\n",
    "camera_helper = CameraHelper(cam)\n",
    "camera_helper.rotateX(math.pi)\n",
    "camera_helper.rotateZ(math.pi/2)\n",
    "scene.add(camera_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d2881d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bcd63bc889044c7a84ce3805449e60e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(aspect=1.3333333333333333, near=0.01, position=(0.0, -10.0, -10.0), projectiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "point_light = PointLight(color=\"#ffffff\", intensity=1, distance=100)\n",
    "scene.add(point_light)\n",
    "\n",
    "#scene.add(camera_helper)\n",
    "controller=OrbitControls(controlling=camera)\n",
    "renderer=Renderer(camera=camera, scene=scene, controls=[controller],width=800,height=600)\n",
    "display(renderer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
